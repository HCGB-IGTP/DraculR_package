
##################################
## Notes and comments: original code
##################################
## Step 1: Import a raw counts table generated by high throughput miRNA sequencing of human plasma libraries. These data will be filtered according to user specified requirements (n = number of samples in the smallest group of interest) and normalised using the Trimmed Mean of M (TMM) method."

## Step 2. Calculate the distribution difference
## The distribution difference between the background and signature miRNA counts is calculated on an individual sample basis allowing the user to upload one to many samples as required. 

## Step 3. Visualise and interpret results",
## An essential feature of DraculR is that it allows users to visualise and assess the values obtained in the results, through sample specific and consolidated graphics including density plots, histograms and tables (Step 3). These features help the user decide on the level of haemolysis that may affect their analysis by providing a new quality metric. Using this metric the user may choose to remove samples from downstream analyses. However, irrespective of whether samples with a Haemolysis Metric above the suggested threshold are removed or retained, the new information may be important to the analysis of their miRNA sequencing data.

## Comma or tab delimited
## Samples in columns, miRNA expression observations in rows
## Column with miRNA names should have the column label “mirna_name”
## miRNA names should be in the miR-base format, e.g. “hsa-miR-123-3p”
## Sample names should be the other column labels
## Sample names should not include white space or special characters

## Legend Help
## The colours used here are consistent across all tabs
## samples from the public data example with a Haemolysis Metric > 1.9 and should be used with caution
## samples from the public data example with a Haemolysis Metric < 1.9 and are considered clear for use
## Haemolysed (dCq) are samples used in an example validation experiment with the qPCR method. These samples had dCq values > 7
## Clear (dCq) are samples used in an example validation experiment with the qPCR method. These samples had dCq values < 7

## The Haemolysis metric described here: https://doi.org/10.3390/genes13071288
## and implemented in the DraculR ShinyR web-based application, performs an in silico quality 
## assessment to detect evidence of haemolysis contamination in the original plasma specimen, 
## assigning each small RNA sequencing dataset into one of two categories
## The classification of ‘Clear’ or ‘Caution’ is designed to alert the user to potential quality control issues in the original plasma specimen.

## Note that samples with total miRNA read counts < 1 million are considered to be poorly sequenced and are recommended to be removed for quality control
##################################

##################################
##### User defined functions #####
##################################

# global objects for imported data calculations
classifier_miRs <- data.frame(
  SYMBOL = c(
    "hsa-miR-106b-3p",
    "hsa-miR-140-3p",
    "hsa-miR-142-5p",
    "hsa-miR-532-5p",
    "hsa-miR-17-5p",
    "hsa-miR-19b-3p",
    "hsa-miR-30c-5p",
    "hsa-miR-324-5p",
    "hsa-miR-192-5p",
    "hsa-miR-660-5p",
    "hsa-miR-186-5p",
    "hsa-miR-425-5p",
    "hsa-miR-25-3p",
    "hsa-miR-363-3p",
    "hsa-miR-183-5p",
    "hsa-miR-451a",
    "hsa-miR-182-5p",
    "hsa-miR-191-5p",
    "hsa-miR-194-5p",
    "hsa-miR-20b-5p"
  )
)

# negate %in%
`%notin%` <- Negate(`%in%`)

# function (x) to count the number of non-zero records in each column (ie per sample)
nonzero <- function(x) sum(x != 0)

# Input Validation Functions
is_csv_or_tsv <- function(input_file, radio_separator, verbose=FALSE) {
  if(radio_separator == ",") { 
    sep_str = "csv"
  } else if(radio_separator == "\t") { 
    sep_str = "tsv"
  }
  
  df.tmp <- read.csv(input_file, sep = radio_separator)
  
  ## check number of columns: if sep is not alright, will just produce 1
  if (dim(df.tmp)[2]==1) {
    print(paste0("+ File provided is not available or extension doesn't match the chosen delimiter"))  
    return(NULL)
  }
  
  print("+ File provided is readable")
  if (verbose) { 
      print("Data example:")
      print(head(df.tmp)[1:5, 1:5]) } 
  return(df.tmp)
}

has_correct_header <- function(df_given, verbose=FALSE) {
  
  if("mir_name" %in% colnames(df_given)) {
    print("+ Header looks OK")
    if (verbose) {  
      print("Colnames: ")
      print(colnames(df_given)) 
    }
    return(TRUE)
    
  } else {
    print("+ Input file must have a column named \"mir_name\" (containing miR IDs). Could not find a column by this name.")
    return(FALSE)
  }
}

at_least_one_library_one_million_reads <- function(df_given, verbose=FALSE) {
  
  library(dplyr)
  colSumLibrary <- summarise_all(df_given, ~if(is.numeric(.)) sum(.) else "Total")
  
  if (verbose) { print("colSumLibrary: ") }
  if (verbose) { print(colSumLibrary) }
  if(any(colSumLibrary>1000000)) {
    print("+ Input file contains some libraries with greater than one million reads.")
    return(TRUE)
    
  } else {
    print("+ Input file contains no libraries with greater than one million reads.")
    return(FALSE)
  }
}

validate_input <- function(raw_data, radio_separator = ",", verbose=FALSE) {
  
  if (verbose) { print("## Validating input file & options ")}
  
  ## Find if readable
  df.tmp <- is_csv_or_tsv(raw_data, radio_separator, verbose)
  if (is.null(df.tmp)) { return(FALSE) }
  
  ## Find if correct header
  if (has_correct_header(df_given = df.tmp, verbose)) {
    ## Find if minimun counts
    if (at_least_one_library_one_million_reads(df_given = df.tmp, verbose)) {
      if (verbose) { print("##################################")}
      return(TRUE)
    }}
  
  return(FALSE)
}

draculR_parse_file <- function(raw_data, sep_input=",", verbose=FALSE) {
  
  ## validate file  
  validation_point <- validate_input(test_file, radio_separator = sep_input, verbose = verbose)
  
  if (validation_point) {
    
  } else {
    print("Some error ocurred, please check instructions or add correct parameters...")
    return()
  }
  
  ##################################
  ## parse original  data
  ##################################
  ## parse
  temp_counts <- read.table(file = raw_data,
                            sep = sep_input,
                            header = TRUE,
                            stringsAsFactors = FALSE) %>%
    dplyr::mutate_if(is.integer, as.numeric) %>%
    as.data.frame() %>%
    tibble::column_to_rownames("mir_name") %>%
    replace(is.na(.), 0)
  
  print("+ Original file:")
  print("dim(temp_counts)")
  print(dim(temp_counts))
  
  ## validate
  # identify samples with < 1 million reads
  lowCounts <- names(temp_counts[, base::colSums(temp_counts) < 1000000])
  
  # remove columns/samples with readcounts less than 1 million
  counts <- temp_counts[, base::colSums(temp_counts) > 1000000]
  
  print("+ Remove columns/samples with readcounts less than 1 million:")
  print("dim(counts)")
  print(dim(counts))
  
  # reduce any individual count less than five to zero
  print("+ Reduce any individual count less than five to zero")
  counts[counts < 5] <- 0
  
  # remove miRNAs with zero counts in all samples
  print("+ Remove miRNAs with zero counts in all samples")
  counts <- counts[ base::rowSums(counts)!=0, ]
  print("dim(counts)")
  print(dim(counts))
  ##################################
  
  return(counts)
  
}

geometric.mean <- function(x,na.rm=TRUE){ 
  ## extracted from psych v2.4.6.26
  if (is.null(nrow(x))) {
    exp(mean(log(x),na.rm=na.rm)) 
  } else {
    exp(apply(log(x),2,mean,na.rm=na.rm))
  } 
}

draculR_parse_counts <- function(counts_df, drop_miRs=c(''), verbose=FALSE, filterNum = 1) {
  
  library(plyr)
  library(edgeR)
  library(magrittr)
  library(dplyr)
  
  #-------------------
  ## Rank counts
  #-------------------
  # rank the samples by read counts and by unique miRs
  # this table will be joined downstream with the distribution difference table
  rank <- base::as.data.frame(base::colSums(counts.test)) %>%
    magrittr::set_colnames(., "readCounts") %>% 
    dplyr::arrange(., -(readCounts)) %>% 
    tibble::rownames_to_column("samplename") %>% 
    dplyr::mutate(., rank_readCounts = 1:nrow(.)) %>% 
    dplyr::full_join(.,
                     as.data.frame(t(numcolwise(nonzero)(as.data.frame(counts.test)))) %>%
                       tibble::rownames_to_column() %>%
                       magrittr::set_colnames(., c("samplename", "unique_miRs")) %>%
                       arrange(., desc(unique_miRs)) %>%
                       mutate(., rank_unique = 1:nrow(.)),
                     by = "samplename")
  
  if (verbose) { 
    print("rank")
    print(rank) 
  }
  #-------------------
  
  #-------------------
  # create the (super) minimal metadata table
  #-------------------
  meta <- data.frame(samplename = rank$samplename,
                     readCounts = rank$readCounts) 
  
  if (verbose) { 
    print("meta")
    print(meta) 
  }
  #-------------------
  
  #-------------------
  # Create a DGEList object
  #-------------------
  print("Calculate normalisation factors and apply to the DGEList object")
  DGEList_public <- edgeR::DGEList(counts = counts.test,
                                   samples = rank)
  
  # calculate normalisation factors and apply to the DGEList object
  DGEList_public <- edgeR::calcNormFactors(DGEList_public, method = "TMM")
  #-------------------
  
  if (verbose) { 
    print("DGEList_public")
    print(DGEList_public) 
  }
  #-------------------
  
  #-------------------
  # calculate the CPMs and reduce
  #-------------------
  print("+ Calculate the CPMs")
  rawCPM <- edgeR::cpm(DGEList_public, log = FALSE)
  
  if (verbose) { 
    print("rawCPM")
    print(rawCPM) 
  }
  
  # remove low expressed genes
  print("+ Remove low expressed genes")
  keep.exprs <- rowSums(rawCPM > 40) >= filterNum
  DGEList_public <- DGEList_public[keep.exprs,, keep.lib.sizes = FALSE]
  
  if (verbose) { 
    
    print("keep.exprs")
    print(keep.exprs)
    print("DGEList_public")
    print(DGEList_public) 
  }
  #-------------------
  
  #-------------------
  ## Distributions differences
  #-------------------
  print("+ Calculate the difference between the geometric mean of the distributions:  1 = classifier, 0 = other, 2 = dropped")
  
  ## Calculate the difference between the geometric mean of the distributions
  ### here we calculate the geometric mean of the classifier distribution and the
  ### "other" ensuring those taken from the classifier list are not included in
  ### other.
  
  # create a vector of sample names for use in the lapply
  varc <- dplyr::select(DGEList_public$samples, samplename) %>%
    tibble::remove_rownames() %>% 
    dplyr::pull(., samplename)
  #-------------------
  
  
  #---------------
  # drop miRNAs if necessary
  #---------------
  
  if (length(drop_miRs)>0) {
    print("+ Drop miRNAs if necessary")  
  }
  
  # define the dropped classifiers as input from the groupCheckboxInput
  dropped <- subset(classifier_miRs, SYMBOL %in% drop_miRs)
  
  # define the final set of classifiers
  final_classifiers <- subset(classifier_miRs, SYMBOL %notin% drop_miRs)
  #---------------
  
  #-------------------
  # calculate the geometric mean of the two distributions (1 = classifier, 0 = other, 2 = dropped)
  #-------------------
  distributionDifference <- lapply(varc, function(x) {
    dtmp <- dplyr::select(as.data.frame(edgeR::cpm(DGEList_public$counts, log = TRUE)), x) %>%
      tibble::rownames_to_column("mirna") %>% 
      mutate(., classifier = as.factor(ifelse(mirna %in% final_classifiers$SYMBOL, 1,
                                              ifelse(mirna %in% dropped$SYMBOL, 2,
                                                     ifelse(mirna %notin% classifier_miRs$SYMBOL, 0, NA)))))
    
    cdat_tmp <- with(dtmp,tapply(get(x), classifier, geometric.mean,na.rm=T))
    
    cdat <- data.frame("classifier"=rownames(cdat_tmp),"geometric.mean"=cdat_tmp)
    
    # calculate the difference between the two geometric means (classifier-other)  
    cdat_out <- dplyr::filter(cdat, classifier == 1)$geometric.mean - dplyr::filter(cdat, classifier == 0)$geometric.mean
    return(cdat_out)
  })
  
  ## set names
  names(distributionDifference) <- varc
  
  unlist_distributionDifference <- do.call(cbind.data.frame, distributionDifference) %>% 
    t() %>%
    magrittr::set_colnames("distributionDifference") %>%
    base::as.data.frame() %>% 
    tibble::rownames_to_column("samplename") %>% 
    dplyr::mutate(., haemoResult = ifelse(distributionDifference < 1.9, "Clear",
                                          ifelse(distributionDifference >= 1.9, "Caution", NA)))
  
  unlist_distributionDifference$haemoResult <- as.factor(unlist_distributionDifference$haemoResult)
  
  #-------------------
  ## join and rename
  #-------------------
  distributionDifference.full <- dplyr::full_join(rank, unlist_distributionDifference, by = "samplename")
  colnames(distributionDifference.full)[6] <- "draculR.score"
  
  return(distributionDifference.full)  
}
##################################

##################################
## data
##################################
## test file
test_file <- file.path("git_repo/DraculR/dataExample/exampleCounts.csv")
test_file <- "/imppc/labs/lslab/share/data/proc_data/20230323_JManye_sRNAseq_Chron/report/miRNA.counts/PE_2022.miRNA.raw.csv"

## Number in smallest group, default=1
counts.test <- draculR_parse_file(raw_data = test_file, sep_input = ",", verbose = FALSE)
draculR_results <- draculR_parse_counts(counts_df = counts.test)

draculR_results

